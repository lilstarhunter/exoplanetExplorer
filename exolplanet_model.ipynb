{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exoplanet Prediction Modeling\n",
    "\n",
    "Over a period of nine years in deep space, the NASA Kepler space telescope has been out on a planet-hunting mission to discover hidden planets outside of our solar system.\n",
    "\n",
    "Below are several machine learning models capable of classifying candidate exoplanets from the raw dataset\n",
    "\n",
    "Data from [NASA Exoplanet Archive](https://exoplanetarchive.ipac.caltech.edu/cgi-bin/TblView/nph-tblView?app=ExoTbls&config=koi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: sklearn in /opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages (0.0)\r\n",
      "Requirement already satisfied, skipping upgrade: scikit-learn in /opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages (from sklearn) (0.23.1)\r\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.19.1 in /opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages (from scikit-learn->sklearn) (1.5.0)\r\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages (from scikit-learn->sklearn) (0.15.1)\r\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in /opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages (from scikit-learn->sklearn) (1.18.5)\r\n",
      "Requirement already satisfied, skipping upgrade: threadpoolctl>=2.0.0 in /opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages (from scikit-learn->sklearn) (2.1.0)\r\n"
     ]
    }
   ],
   "source": [
    "# Update sklearn to prevent version mismatches\n",
    "!pip install sklearn --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: joblib in /opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages (0.15.1)\r\n"
     ]
    }
   ],
   "source": [
    "# install joblib for saving\n",
    "# Restart kernel after installing \n",
    "!pip install joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring and Selecting the Data\n",
    "\n",
    "This dataset is a cumulative record of all observed Kepler \"objects of interest\" and contains an extensive data directory. \n",
    "\n",
    "**Exoplanet Achive Information**: The disposition or label in the literature for the exoplanet candidate. One of CANDIDATE, FALSE POSITIVE, NOT DISPOSITIONED or CONFIRMED. (**koi_disposition**)\n",
    "\n",
    "**Project Disposition Columns**: NASA flags used to identify or assign the foreign body. Labeled with _flag_ and not useful for generating a model.\n",
    "\n",
    "**Transit Properties**: Calculated parameters of the object such as  Orbital Period, Transit Epoch, Planet-Star Radius Ratio, Planet-Star Distance over Star Radius and Impact Parameter. _Transit properties contain uncertainty values and are identified with a suffix _err. The margin of error is NOT included in the model_\n",
    "\n",
    "**Stellar Parameters**: Stellar parameters are observational data used to determine stellar physics. These include effective temperature, surface gravity, metallicity, radius, mass, and ageCalculated parameters of the object such as  Orbital Period, Transit Epoch, Planet-Star Radius Ratio, Planet-Star Distance over Star Radius and Impact Parameter. _Stellar properties contain uncertainty values and are identified with a suffix _err. The margin of error is NOT included in the model_\n",
    "\n",
    "**KIC Parameters**: Physical properties and target identifier.\n",
    "\n",
    "[Full Directory of Data Columns Definitions](https://exoplanetarchive.ipac.caltech.edu/docs/API_kepcandidate_columns.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the CSV and Perform Basic Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['koi_disposition', 'koi_fpflag_nt', 'koi_fpflag_ss', 'koi_fpflag_co',\n",
       "       'koi_fpflag_ec', 'koi_period', 'koi_period_err1', 'koi_period_err2',\n",
       "       'koi_time0bk', 'koi_time0bk_err1', 'koi_time0bk_err2', 'koi_impact',\n",
       "       'koi_impact_err1', 'koi_impact_err2', 'koi_duration',\n",
       "       'koi_duration_err1', 'koi_duration_err2', 'koi_depth', 'koi_depth_err1',\n",
       "       'koi_depth_err2', 'koi_prad', 'koi_prad_err1', 'koi_prad_err2',\n",
       "       'koi_teq', 'koi_insol', 'koi_insol_err1', 'koi_insol_err2',\n",
       "       'koi_model_snr', 'koi_tce_plnt_num', 'koi_steff', 'koi_steff_err1',\n",
       "       'koi_steff_err2', 'koi_slogg', 'koi_slogg_err1', 'koi_slogg_err2',\n",
       "       'koi_srad', 'koi_srad_err1', 'koi_srad_err2', 'ra', 'dec',\n",
       "       'koi_kepmag'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"exoplanet_data.csv\")\n",
    "\n",
    "# Drop the null columns where all values are null\n",
    "df = df.dropna(axis='columns', how='all')\n",
    "\n",
    "# Drop the null rows\n",
    "df = df.dropna()\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>koi_fpflag_nt</th>\n",
       "      <th>koi_fpflag_ss</th>\n",
       "      <th>koi_fpflag_co</th>\n",
       "      <th>koi_fpflag_ec</th>\n",
       "      <th>koi_period</th>\n",
       "      <th>koi_time0bk</th>\n",
       "      <th>koi_impact</th>\n",
       "      <th>koi_duration</th>\n",
       "      <th>koi_depth</th>\n",
       "      <th>koi_prad</th>\n",
       "      <th>koi_teq</th>\n",
       "      <th>koi_insol</th>\n",
       "      <th>koi_model_snr</th>\n",
       "      <th>koi_steff</th>\n",
       "      <th>koi_srad</th>\n",
       "      <th>ra</th>\n",
       "      <th>dec</th>\n",
       "      <th>koi_kepmag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>54.418383</td>\n",
       "      <td>162.513840</td>\n",
       "      <td>0.586</td>\n",
       "      <td>4.50700</td>\n",
       "      <td>874.8</td>\n",
       "      <td>2.83</td>\n",
       "      <td>443</td>\n",
       "      <td>9.11</td>\n",
       "      <td>25.8</td>\n",
       "      <td>5455</td>\n",
       "      <td>0.927</td>\n",
       "      <td>291.93423</td>\n",
       "      <td>48.141651</td>\n",
       "      <td>15.347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19.899140</td>\n",
       "      <td>175.850252</td>\n",
       "      <td>0.969</td>\n",
       "      <td>1.78220</td>\n",
       "      <td>10829.0</td>\n",
       "      <td>14.60</td>\n",
       "      <td>638</td>\n",
       "      <td>39.30</td>\n",
       "      <td>76.3</td>\n",
       "      <td>5853</td>\n",
       "      <td>0.868</td>\n",
       "      <td>297.00482</td>\n",
       "      <td>48.134129</td>\n",
       "      <td>15.436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.736952</td>\n",
       "      <td>170.307565</td>\n",
       "      <td>1.276</td>\n",
       "      <td>2.40641</td>\n",
       "      <td>8079.2</td>\n",
       "      <td>33.46</td>\n",
       "      <td>1395</td>\n",
       "      <td>891.96</td>\n",
       "      <td>505.6</td>\n",
       "      <td>5805</td>\n",
       "      <td>0.791</td>\n",
       "      <td>285.53461</td>\n",
       "      <td>48.285210</td>\n",
       "      <td>15.597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.525592</td>\n",
       "      <td>171.595550</td>\n",
       "      <td>0.701</td>\n",
       "      <td>1.65450</td>\n",
       "      <td>603.3</td>\n",
       "      <td>2.75</td>\n",
       "      <td>1406</td>\n",
       "      <td>926.16</td>\n",
       "      <td>40.9</td>\n",
       "      <td>6031</td>\n",
       "      <td>1.046</td>\n",
       "      <td>288.75488</td>\n",
       "      <td>48.226200</td>\n",
       "      <td>15.509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.134435</td>\n",
       "      <td>172.979370</td>\n",
       "      <td>0.762</td>\n",
       "      <td>3.14020</td>\n",
       "      <td>686.0</td>\n",
       "      <td>2.77</td>\n",
       "      <td>1160</td>\n",
       "      <td>427.65</td>\n",
       "      <td>40.2</td>\n",
       "      <td>6046</td>\n",
       "      <td>0.972</td>\n",
       "      <td>296.28613</td>\n",
       "      <td>48.224670</td>\n",
       "      <td>15.714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   koi_fpflag_nt  koi_fpflag_ss  koi_fpflag_co  koi_fpflag_ec  koi_period  \\\n",
       "0              0              0              0              0   54.418383   \n",
       "1              0              1              0              0   19.899140   \n",
       "2              0              1              0              0    1.736952   \n",
       "3              0              0              0              0    2.525592   \n",
       "4              0              0              0              0    4.134435   \n",
       "\n",
       "   koi_time0bk  koi_impact  koi_duration  koi_depth  koi_prad  koi_teq  \\\n",
       "0   162.513840       0.586       4.50700      874.8      2.83      443   \n",
       "1   175.850252       0.969       1.78220    10829.0     14.60      638   \n",
       "2   170.307565       1.276       2.40641     8079.2     33.46     1395   \n",
       "3   171.595550       0.701       1.65450      603.3      2.75     1406   \n",
       "4   172.979370       0.762       3.14020      686.0      2.77     1160   \n",
       "\n",
       "   koi_insol  koi_model_snr  koi_steff  koi_srad         ra        dec  \\\n",
       "0       9.11           25.8       5455     0.927  291.93423  48.141651   \n",
       "1      39.30           76.3       5853     0.868  297.00482  48.134129   \n",
       "2     891.96          505.6       5805     0.791  285.53461  48.285210   \n",
       "3     926.16           40.9       6031     1.046  288.75488  48.226200   \n",
       "4     427.65           40.2       6046     0.972  296.28613  48.224670   \n",
       "\n",
       "   koi_kepmag  \n",
       "0      15.347  \n",
       "1      15.436  \n",
       "2      15.597  \n",
       "3      15.509  \n",
       "4      15.714  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing unwanted columns from dataset\n",
    "exo_df = df[['koi_fpflag_nt', 'koi_fpflag_ss', 'koi_fpflag_co',\n",
    "       'koi_fpflag_ec', 'koi_period', 'koi_time0bk', 'koi_impact','koi_duration', 'koi_depth', 'koi_prad', 'koi_teq', 'koi_insol','koi_model_snr', 'koi_steff', 'koi_srad','ra', 'dec',\n",
    "       'koi_kepmag']]\n",
    "exo_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CONFIRMED', 'FALSE POSITIVE', 'CANDIDATE'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the classifiers for the koi_disposition\n",
    "df[\"koi_disposition\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign X(features) and y (target) from the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6991, 18) (6991,)\n"
     ]
    }
   ],
   "source": [
    "X = exo_df\n",
    "y = df[\"koi_disposition\"]\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data into testing and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>koi_fpflag_nt</th>\n",
       "      <th>koi_fpflag_ss</th>\n",
       "      <th>koi_fpflag_co</th>\n",
       "      <th>koi_fpflag_ec</th>\n",
       "      <th>koi_period</th>\n",
       "      <th>koi_time0bk</th>\n",
       "      <th>koi_impact</th>\n",
       "      <th>koi_duration</th>\n",
       "      <th>koi_depth</th>\n",
       "      <th>koi_prad</th>\n",
       "      <th>koi_teq</th>\n",
       "      <th>koi_insol</th>\n",
       "      <th>koi_model_snr</th>\n",
       "      <th>koi_steff</th>\n",
       "      <th>koi_srad</th>\n",
       "      <th>ra</th>\n",
       "      <th>dec</th>\n",
       "      <th>koi_kepmag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6122</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.768901</td>\n",
       "      <td>133.077240</td>\n",
       "      <td>0.150</td>\n",
       "      <td>3.61600</td>\n",
       "      <td>123.1</td>\n",
       "      <td>1.24</td>\n",
       "      <td>1017</td>\n",
       "      <td>253.30</td>\n",
       "      <td>10.8</td>\n",
       "      <td>5737</td>\n",
       "      <td>1.125</td>\n",
       "      <td>294.40472</td>\n",
       "      <td>39.351681</td>\n",
       "      <td>14.725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6370</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.733726</td>\n",
       "      <td>132.020050</td>\n",
       "      <td>0.291</td>\n",
       "      <td>2.30900</td>\n",
       "      <td>114.6</td>\n",
       "      <td>0.86</td>\n",
       "      <td>1867</td>\n",
       "      <td>2891.64</td>\n",
       "      <td>13.8</td>\n",
       "      <td>5855</td>\n",
       "      <td>0.797</td>\n",
       "      <td>284.50391</td>\n",
       "      <td>42.463860</td>\n",
       "      <td>15.770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2879</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.652707</td>\n",
       "      <td>134.460380</td>\n",
       "      <td>0.970</td>\n",
       "      <td>79.89690</td>\n",
       "      <td>641.1</td>\n",
       "      <td>3.21</td>\n",
       "      <td>989</td>\n",
       "      <td>226.81</td>\n",
       "      <td>254.3</td>\n",
       "      <td>6328</td>\n",
       "      <td>0.963</td>\n",
       "      <td>295.50211</td>\n",
       "      <td>38.983540</td>\n",
       "      <td>13.099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.953547</td>\n",
       "      <td>174.662240</td>\n",
       "      <td>0.300</td>\n",
       "      <td>2.63120</td>\n",
       "      <td>875.4</td>\n",
       "      <td>2.25</td>\n",
       "      <td>696</td>\n",
       "      <td>55.37</td>\n",
       "      <td>38.4</td>\n",
       "      <td>4768</td>\n",
       "      <td>0.779</td>\n",
       "      <td>291.15878</td>\n",
       "      <td>40.750271</td>\n",
       "      <td>15.660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.959319</td>\n",
       "      <td>172.258529</td>\n",
       "      <td>0.831</td>\n",
       "      <td>2.22739</td>\n",
       "      <td>9802.0</td>\n",
       "      <td>12.21</td>\n",
       "      <td>1103</td>\n",
       "      <td>349.40</td>\n",
       "      <td>696.5</td>\n",
       "      <td>5712</td>\n",
       "      <td>1.082</td>\n",
       "      <td>292.16705</td>\n",
       "      <td>48.727589</td>\n",
       "      <td>15.263</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      koi_fpflag_nt  koi_fpflag_ss  koi_fpflag_co  koi_fpflag_ec  koi_period  \\\n",
       "6122              0              0              0              0    6.768901   \n",
       "6370              0              1              0              1    0.733726   \n",
       "2879              1              0              0              0    7.652707   \n",
       "107               0              0              0              0    7.953547   \n",
       "29                0              0              0              0    4.959319   \n",
       "\n",
       "      koi_time0bk  koi_impact  koi_duration  koi_depth  koi_prad  koi_teq  \\\n",
       "6122   133.077240       0.150       3.61600      123.1      1.24     1017   \n",
       "6370   132.020050       0.291       2.30900      114.6      0.86     1867   \n",
       "2879   134.460380       0.970      79.89690      641.1      3.21      989   \n",
       "107    174.662240       0.300       2.63120      875.4      2.25      696   \n",
       "29     172.258529       0.831       2.22739     9802.0     12.21     1103   \n",
       "\n",
       "      koi_insol  koi_model_snr  koi_steff  koi_srad         ra        dec  \\\n",
       "6122     253.30           10.8       5737     1.125  294.40472  39.351681   \n",
       "6370    2891.64           13.8       5855     0.797  284.50391  42.463860   \n",
       "2879     226.81          254.3       6328     0.963  295.50211  38.983540   \n",
       "107       55.37           38.4       4768     0.779  291.15878  40.750271   \n",
       "29       349.40          696.5       5712     1.082  292.16705  48.727589   \n",
       "\n",
       "      koi_kepmag  \n",
       "6122      14.725  \n",
       "6370      15.770  \n",
       "2879      13.099  \n",
       "107       15.660  \n",
       "29        15.263  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MinMaxScalar to fit and transform X features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit Transform using MinMaxScalar for X features\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "X_minmax = MinMaxScaler().fit(X_train)\n",
    "\n",
    "X_train_minmax = X_minmax.transform(X_train)\n",
    "X_test_minmax = X_minmax.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Encoding for target (y) value (neural networks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>disposition_types</th>\n",
       "      <th>disposition_types_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  disposition_types  disposition_types_cat\n",
       "0         CANDIDATE                      0\n",
       "1         CONFIRMED                      1\n",
       "2    FALSE POSITIVE                      2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualize Label Encoding\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "disposition_types = ('CANDIDATE', 'CONFIRMED', 'FALSE POSITIVE')\n",
    "disposition_df = pd.DataFrame(disposition_types, columns=['disposition_types'])# converting type of columns to 'category'\n",
    "\n",
    "# creating instance of labelencoder\n",
    "labelencoder = LabelEncoder()\n",
    "\n",
    "# Assigning numerical values and storing in another column\n",
    "disposition_df['disposition_types_cat'] = labelencoder.fit_transform(disposition_df['disposition_types'])\n",
    "disposition_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Label encoding on train and test data set for y\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "encoded_y_train = label_encoder.transform(y_train)\n",
    "encoded_y_test = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create one-hot encoding for neural network\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "y_train_categorical = to_categorical(encoded_y_train)\n",
    "y_test_categorical = to_categorical(encoded_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine Classifiers: Linear\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.8085065802021744\n",
      "Testing Data Score: 0.7980549199084668\n"
     ]
    }
   ],
   "source": [
    "# Create the SVC Model\n",
    "from sklearn.svm import SVC \n",
    "model_SVC = SVC(kernel='linear')\n",
    "model_SVC.fit(X_train_minmax, y_train)\n",
    "\n",
    "print(f\"Training Data Score: {model_SVC.score(X_train_minmax, y_train)}\")\n",
    "print(f\"Testing Data Score: {model_SVC.score(X_test_minmax, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypertune SVM using GridSearch CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the GridSearchCV model\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'C': [1, 5, 10, 50],\n",
    "              'gamma': [0.0001, 0.0005, 0.001, 0.005]}\n",
    "grid = GridSearchCV(model_SVC, param_grid, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] C=1, gamma=0.0001 ...............................................\n",
      "[CV] ................... C=1, gamma=0.0001, score=0.819, total=   0.1s\n",
      "[CV] C=1, gamma=0.0001 ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................... C=1, gamma=0.0001, score=0.803, total=   0.1s\n",
      "[CV] C=1, gamma=0.0001 ...............................................\n",
      "[CV] ................... C=1, gamma=0.0001, score=0.807, total=   0.1s\n",
      "[CV] C=1, gamma=0.0001 ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................... C=1, gamma=0.0001, score=0.782, total=   0.1s\n",
      "[CV] C=1, gamma=0.0001 ...............................................\n",
      "[CV] ................... C=1, gamma=0.0001, score=0.807, total=   0.1s\n",
      "[CV] C=1, gamma=0.0005 ...............................................\n",
      "[CV] ................... C=1, gamma=0.0005, score=0.819, total=   0.1s\n",
      "[CV] C=1, gamma=0.0005 ...............................................\n",
      "[CV] ................... C=1, gamma=0.0005, score=0.803, total=   0.1s\n",
      "[CV] C=1, gamma=0.0005 ...............................................\n",
      "[CV] ................... C=1, gamma=0.0005, score=0.807, total=   0.1s\n",
      "[CV] C=1, gamma=0.0005 ...............................................\n",
      "[CV] ................... C=1, gamma=0.0005, score=0.782, total=   0.1s\n",
      "[CV] C=1, gamma=0.0005 ...............................................\n",
      "[CV] ................... C=1, gamma=0.0005, score=0.807, total=   0.1s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] .................... C=1, gamma=0.001, score=0.819, total=   0.1s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] .................... C=1, gamma=0.001, score=0.803, total=   0.1s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] .................... C=1, gamma=0.001, score=0.807, total=   0.1s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] .................... C=1, gamma=0.001, score=0.782, total=   0.1s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] .................... C=1, gamma=0.001, score=0.807, total=   0.1s\n",
      "[CV] C=1, gamma=0.005 ................................................\n",
      "[CV] .................... C=1, gamma=0.005, score=0.819, total=   0.1s\n",
      "[CV] C=1, gamma=0.005 ................................................\n",
      "[CV] .................... C=1, gamma=0.005, score=0.803, total=   0.1s\n",
      "[CV] C=1, gamma=0.005 ................................................\n",
      "[CV] .................... C=1, gamma=0.005, score=0.807, total=   0.1s\n",
      "[CV] C=1, gamma=0.005 ................................................\n",
      "[CV] .................... C=1, gamma=0.005, score=0.782, total=   0.1s\n",
      "[CV] C=1, gamma=0.005 ................................................\n",
      "[CV] .................... C=1, gamma=0.005, score=0.807, total=   0.1s\n",
      "[CV] C=5, gamma=0.0001 ...............................................\n",
      "[CV] ................... C=5, gamma=0.0001, score=0.830, total=   0.1s\n",
      "[CV] C=5, gamma=0.0001 ...............................................\n",
      "[CV] ................... C=5, gamma=0.0001, score=0.802, total=   0.2s\n",
      "[CV] C=5, gamma=0.0001 ...............................................\n",
      "[CV] ................... C=5, gamma=0.0001, score=0.819, total=   0.2s\n",
      "[CV] C=5, gamma=0.0001 ...............................................\n",
      "[CV] ................... C=5, gamma=0.0001, score=0.798, total=   0.1s\n",
      "[CV] C=5, gamma=0.0001 ...............................................\n",
      "[CV] ................... C=5, gamma=0.0001, score=0.815, total=   0.2s\n",
      "[CV] C=5, gamma=0.0005 ...............................................\n",
      "[CV] ................... C=5, gamma=0.0005, score=0.830, total=   0.2s\n",
      "[CV] C=5, gamma=0.0005 ...............................................\n",
      "[CV] ................... C=5, gamma=0.0005, score=0.802, total=   0.1s\n",
      "[CV] C=5, gamma=0.0005 ...............................................\n",
      "[CV] ................... C=5, gamma=0.0005, score=0.819, total=   0.2s\n",
      "[CV] C=5, gamma=0.0005 ...............................................\n",
      "[CV] ................... C=5, gamma=0.0005, score=0.798, total=   0.2s\n",
      "[CV] C=5, gamma=0.0005 ...............................................\n",
      "[CV] ................... C=5, gamma=0.0005, score=0.815, total=   0.2s\n",
      "[CV] C=5, gamma=0.001 ................................................\n",
      "[CV] .................... C=5, gamma=0.001, score=0.830, total=   0.2s\n",
      "[CV] C=5, gamma=0.001 ................................................\n",
      "[CV] .................... C=5, gamma=0.001, score=0.802, total=   0.2s\n",
      "[CV] C=5, gamma=0.001 ................................................\n",
      "[CV] .................... C=5, gamma=0.001, score=0.819, total=   0.2s\n",
      "[CV] C=5, gamma=0.001 ................................................\n",
      "[CV] .................... C=5, gamma=0.001, score=0.798, total=   0.2s\n",
      "[CV] C=5, gamma=0.001 ................................................\n",
      "[CV] .................... C=5, gamma=0.001, score=0.815, total=   0.2s\n",
      "[CV] C=5, gamma=0.005 ................................................\n",
      "[CV] .................... C=5, gamma=0.005, score=0.830, total=   0.2s\n",
      "[CV] C=5, gamma=0.005 ................................................\n",
      "[CV] .................... C=5, gamma=0.005, score=0.802, total=   0.2s\n",
      "[CV] C=5, gamma=0.005 ................................................\n",
      "[CV] .................... C=5, gamma=0.005, score=0.819, total=   0.2s\n",
      "[CV] C=5, gamma=0.005 ................................................\n",
      "[CV] .................... C=5, gamma=0.005, score=0.798, total=   0.1s\n",
      "[CV] C=5, gamma=0.005 ................................................\n",
      "[CV] .................... C=5, gamma=0.005, score=0.815, total=   0.2s\n",
      "[CV] C=10, gamma=0.0001 ..............................................\n",
      "[CV] .................. C=10, gamma=0.0001, score=0.836, total=   0.2s\n",
      "[CV] C=10, gamma=0.0001 ..............................................\n",
      "[CV] .................. C=10, gamma=0.0001, score=0.802, total=   0.2s\n",
      "[CV] C=10, gamma=0.0001 ..............................................\n",
      "[CV] .................. C=10, gamma=0.0001, score=0.818, total=   0.2s\n",
      "[CV] C=10, gamma=0.0001 ..............................................\n",
      "[CV] .................. C=10, gamma=0.0001, score=0.803, total=   0.2s\n",
      "[CV] C=10, gamma=0.0001 ..............................................\n",
      "[CV] .................. C=10, gamma=0.0001, score=0.817, total=   0.2s\n",
      "[CV] C=10, gamma=0.0005 ..............................................\n",
      "[CV] .................. C=10, gamma=0.0005, score=0.836, total=   0.2s\n",
      "[CV] C=10, gamma=0.0005 ..............................................\n",
      "[CV] .................. C=10, gamma=0.0005, score=0.802, total=   0.2s\n",
      "[CV] C=10, gamma=0.0005 ..............................................\n",
      "[CV] .................. C=10, gamma=0.0005, score=0.818, total=   0.2s\n",
      "[CV] C=10, gamma=0.0005 ..............................................\n",
      "[CV] .................. C=10, gamma=0.0005, score=0.803, total=   0.1s\n",
      "[CV] C=10, gamma=0.0005 ..............................................\n",
      "[CV] .................. C=10, gamma=0.0005, score=0.817, total=   0.2s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ................... C=10, gamma=0.001, score=0.836, total=   0.2s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ................... C=10, gamma=0.001, score=0.802, total=   0.2s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ................... C=10, gamma=0.001, score=0.818, total=   0.2s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ................... C=10, gamma=0.001, score=0.803, total=   0.2s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ................... C=10, gamma=0.001, score=0.817, total=   0.2s\n",
      "[CV] C=10, gamma=0.005 ...............................................\n",
      "[CV] ................... C=10, gamma=0.005, score=0.836, total=   0.2s\n",
      "[CV] C=10, gamma=0.005 ...............................................\n",
      "[CV] ................... C=10, gamma=0.005, score=0.802, total=   0.2s\n",
      "[CV] C=10, gamma=0.005 ...............................................\n",
      "[CV] ................... C=10, gamma=0.005, score=0.818, total=   0.2s\n",
      "[CV] C=10, gamma=0.005 ...............................................\n",
      "[CV] ................... C=10, gamma=0.005, score=0.803, total=   0.2s\n",
      "[CV] C=10, gamma=0.005 ...............................................\n",
      "[CV] ................... C=10, gamma=0.005, score=0.817, total=   0.2s\n",
      "[CV] C=50, gamma=0.0001 ..............................................\n",
      "[CV] .................. C=50, gamma=0.0001, score=0.845, total=   0.2s\n",
      "[CV] C=50, gamma=0.0001 ..............................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................. C=50, gamma=0.0001, score=0.809, total=   0.2s\n",
      "[CV] C=50, gamma=0.0001 ..............................................\n",
      "[CV] .................. C=50, gamma=0.0001, score=0.816, total=   0.2s\n",
      "[CV] C=50, gamma=0.0001 ..............................................\n",
      "[CV] .................. C=50, gamma=0.0001, score=0.807, total=   0.2s\n",
      "[CV] C=50, gamma=0.0001 ..............................................\n",
      "[CV] .................. C=50, gamma=0.0001, score=0.821, total=   0.2s\n",
      "[CV] C=50, gamma=0.0005 ..............................................\n",
      "[CV] .................. C=50, gamma=0.0005, score=0.845, total=   0.2s\n",
      "[CV] C=50, gamma=0.0005 ..............................................\n",
      "[CV] .................. C=50, gamma=0.0005, score=0.809, total=   0.2s\n",
      "[CV] C=50, gamma=0.0005 ..............................................\n",
      "[CV] .................. C=50, gamma=0.0005, score=0.816, total=   0.2s\n",
      "[CV] C=50, gamma=0.0005 ..............................................\n",
      "[CV] .................. C=50, gamma=0.0005, score=0.807, total=   0.2s\n",
      "[CV] C=50, gamma=0.0005 ..............................................\n",
      "[CV] .................. C=50, gamma=0.0005, score=0.821, total=   0.2s\n",
      "[CV] C=50, gamma=0.001 ...............................................\n",
      "[CV] ................... C=50, gamma=0.001, score=0.845, total=   0.2s\n",
      "[CV] C=50, gamma=0.001 ...............................................\n",
      "[CV] ................... C=50, gamma=0.001, score=0.809, total=   0.2s\n",
      "[CV] C=50, gamma=0.001 ...............................................\n",
      "[CV] ................... C=50, gamma=0.001, score=0.816, total=   0.2s\n",
      "[CV] C=50, gamma=0.001 ...............................................\n",
      "[CV] ................... C=50, gamma=0.001, score=0.807, total=   0.2s\n",
      "[CV] C=50, gamma=0.001 ...............................................\n",
      "[CV] ................... C=50, gamma=0.001, score=0.821, total=   0.2s\n",
      "[CV] C=50, gamma=0.005 ...............................................\n",
      "[CV] ................... C=50, gamma=0.005, score=0.845, total=   0.2s\n",
      "[CV] C=50, gamma=0.005 ...............................................\n",
      "[CV] ................... C=50, gamma=0.005, score=0.809, total=   0.2s\n",
      "[CV] C=50, gamma=0.005 ...............................................\n",
      "[CV] ................... C=50, gamma=0.005, score=0.816, total=   0.2s\n",
      "[CV] C=50, gamma=0.005 ...............................................\n",
      "[CV] ................... C=50, gamma=0.005, score=0.807, total=   0.2s\n",
      "[CV] C=50, gamma=0.005 ...............................................\n",
      "[CV] ................... C=50, gamma=0.005, score=0.821, total=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  80 out of  80 | elapsed:   13.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 50, 'gamma': 0.0001}\n"
     ]
    }
   ],
   "source": [
    "# Fit the Model using the grid search estimator\n",
    "grid.fit(X_train_minmax, encoded_y_train)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 50, 'gamma': 0.0001}\n",
      "Best SVG score: 0.8195667993508904\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best Parameters: {grid.best_params_}\")\n",
    "print(f\"Best SVG score: {grid.best_score_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and Fit Hypertune SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.8241464810223155\n",
      "Testing Data Score: 0.8100686498855835\n"
     ]
    }
   ],
   "source": [
    "model_SVC2 = SVC(C=50, gamma= 0.0001, kernel='linear')\n",
    "model_SVC2.fit(X_train_minmax, encoded_y_train)\n",
    "print(f\"Training Data Score: {model_SVC2.score(X_train_minmax, encoded_y_train)}\")\n",
    "print(f\"Testing Data Score: {model_SVC2.score(X_test_minmax, encoded_y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Models/lmstein_svm.sav']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "filename = 'Models/lmstein_svm.sav'\n",
    "joblib.dump(\"lmstein\", filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.8136563036429525\n",
      "Testing Data Score: 0.8037757437070938\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Create a logistic regression model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression()\n",
    "\n",
    "# Fit the model to the data\n",
    "classifier.fit(X_train_minmax, y_train)\n",
    "\n",
    "\n",
    "# Scoer the model\n",
    "print(f\"Training Data Score: {classifier.score(X_train_minmax, y_train)}\")\n",
    "print(f\"Testing Data Score: {classifier.score(X_test_minmax, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypertune the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "[CV] C=1, penalty=l1 .................................................\n",
      "[CV] ....................... C=1, penalty=l1, score=nan, total=   0.0s\n",
      "[CV] C=1, penalty=l1 .................................................\n",
      "[CV] ....................... C=1, penalty=l1, score=nan, total=   0.0s\n",
      "[CV] C=1, penalty=l1 .................................................\n",
      "[CV] ....................... C=1, penalty=l1, score=nan, total=   0.0s\n",
      "[CV] C=1, penalty=l1 .................................................\n",
      "[CV] ....................... C=1, penalty=l1, score=nan, total=   0.0s\n",
      "[CV] C=1, penalty=l1 .................................................\n",
      "[CV] ....................... C=1, penalty=l1, score=nan, total=   0.0s\n",
      "[CV] C=1, penalty=l2 .................................................\n",
      "[CV] ..................... C=1, penalty=l2, score=0.828, total=   0.1s\n",
      "[CV] C=1, penalty=l2 .................................................\n",
      "[CV] ..................... C=1, penalty=l2, score=0.803, total=   0.1s\n",
      "[CV] C=1, penalty=l2 .................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... C=1, penalty=l2, score=0.815, total=   0.1s\n",
      "[CV] C=1, penalty=l2 .................................................\n",
      "[CV] ..................... C=1, penalty=l2, score=0.797, total=   0.1s\n",
      "[CV] C=1, penalty=l2 .................................................\n",
      "[CV] ..................... C=1, penalty=l2, score=0.806, total=   0.1s\n",
      "[CV] C=2, penalty=l1 .................................................\n",
      "[CV] ....................... C=2, penalty=l1, score=nan, total=   0.0s\n",
      "[CV] C=2, penalty=l1 .................................................\n",
      "[CV] ....................... C=2, penalty=l1, score=nan, total=   0.0s\n",
      "[CV] C=2, penalty=l1 .................................................\n",
      "[CV] ....................... C=2, penalty=l1, score=nan, total=   0.0s\n",
      "[CV] C=2, penalty=l1 .................................................\n",
      "[CV] ....................... C=2, penalty=l1, score=nan, total=   0.0s\n",
      "[CV] C=2, penalty=l1 .................................................\n",
      "[CV] ....................... C=2, penalty=l1, score=nan, total=   0.0s\n",
      "[CV] C=2, penalty=l2 .................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... C=2, penalty=l2, score=0.830, total=   0.1s\n",
      "[CV] C=2, penalty=l2 .................................................\n",
      "[CV] ..................... C=2, penalty=l2, score=0.803, total=   0.1s\n",
      "[CV] C=2, penalty=l2 .................................................\n",
      "[CV] ..................... C=2, penalty=l2, score=0.816, total=   0.1s\n",
      "[CV] C=2, penalty=l2 .................................................\n",
      "[CV] ..................... C=2, penalty=l2, score=0.800, total=   0.1s\n",
      "[CV] C=2, penalty=l2 .................................................\n",
      "[CV] ..................... C=2, penalty=l2, score=0.814, total=   0.1s\n",
      "[CV] C=10, penalty=l1 ................................................\n",
      "[CV] ...................... C=10, penalty=l1, score=nan, total=   0.0s\n",
      "[CV] C=10, penalty=l1 ................................................\n",
      "[CV] ...................... C=10, penalty=l1, score=nan, total=   0.0s\n",
      "[CV] C=10, penalty=l1 ................................................\n",
      "[CV] ...................... C=10, penalty=l1, score=nan, total=   0.0s\n",
      "[CV] C=10, penalty=l1 ................................................\n",
      "[CV] ...................... C=10, penalty=l1, score=nan, total=   0.0s\n",
      "[CV] C=10, penalty=l1 ................................................\n",
      "[CV] ...................... C=10, penalty=l1, score=nan, total=   0.0s\n",
      "[CV] C=10, penalty=l2 ................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................... C=10, penalty=l2, score=0.844, total=   0.1s\n",
      "[CV] C=10, penalty=l2 ................................................\n",
      "[CV] .................... C=10, penalty=l2, score=0.810, total=   0.1s\n",
      "[CV] C=10, penalty=l2 ................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................... C=10, penalty=l2, score=0.811, total=   0.1s\n",
      "[CV] C=10, penalty=l2 ................................................\n",
      "[CV] .................... C=10, penalty=l2, score=0.804, total=   0.1s\n",
      "[CV] C=10, penalty=l2 ................................................\n",
      "[CV] .................... C=10, penalty=l2, score=0.822, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    1.4s finished\n",
      "/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=LogisticRegression(),\n",
       "             param_grid={'C': [1, 2, 10], 'penalty': ['l1', 'l2']}, verbose=3)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the GridSearchCV model\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "params = {\"C\": [1,2,10], 'penalty': ['l1', 'l2']}\n",
    "grid2 =GridSearchCV(classifier,params,verbose=3)\n",
    "grid2.fit(X_train_minmax, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 10, 'penalty': 'l2'}\n",
      "Best SVG score: 0.8182318311150569\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best Parameters: {grid2.best_params_}\")\n",
    "print(f\"Best SVG score: {grid2.best_score_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and Fit Hypertuned Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.8222391760442495\n",
      "Testing Data Score: 0.8094965675057209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "classifier2 = LogisticRegression(C=10, penalty=\"l2\")\n",
    "\n",
    "# Fit the model to the data\n",
    "classifier2.fit(X_train_minmax, y_train)\n",
    "\n",
    "print(f\"Training Data Score: {classifier2.score(X_train_minmax, y_train)}\")\n",
    "print(f\"Testing Data Score: {classifier2.score(X_test_minmax, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Models/lmstein_lr.sav']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "filename = 'Models/lmstein_lr.sav'\n",
    "joblib.dump(\"lmstein\", filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest \n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.13546803817191622, 'koi_model_snr'),\n",
       " (0.13299237494425487, 'koi_fpflag_nt'),\n",
       " (0.13249580301821748, 'koi_fpflag_co'),\n",
       " (0.11058041500360828, 'koi_fpflag_ss'),\n",
       " (0.07686629078110711, 'koi_prad'),\n",
       " (0.048965550016794195, 'koi_depth'),\n",
       " (0.04470705483010433, 'koi_period'),\n",
       " (0.043355138795892874, 'koi_fpflag_ec'),\n",
       " (0.03850599774682626, 'koi_impact'),\n",
       " (0.03230489190460342, 'koi_teq'),\n",
       " (0.03195531826675794, 'koi_duration'),\n",
       " (0.03003325797715433, 'koi_time0bk'),\n",
       " (0.026247631927784374, 'koi_insol'),\n",
       " (0.025053450496244068, 'koi_steff'),\n",
       " (0.023017253805654603, 'ra'),\n",
       " (0.02299711454219339, 'koi_srad'),\n",
       " (0.02253738004032889, 'dec'),\n",
       " (0.021917037730557386, 'koi_kepmag')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# STEP 1: Create a random forest classifier\n",
    "rf = RandomForestClassifier(n_estimators=200)\n",
    "rf = rf.fit(X_train_minmax, encoded_y_train)\n",
    "score = rf.score(X_test_minmax, encoded_y_test)\n",
    "\n",
    "# STEP 2: Auto calculate feature importance\n",
    "importances = rf.feature_importances_\n",
    "importances\n",
    "\n",
    "# Sort the features by their importance\n",
    "sorted(zip(rf.feature_importances_, X.columns), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Testing Score: 0.9084668192219679\n"
     ]
    }
   ],
   "source": [
    "print(f\"Random Forest Testing Score: {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypertune the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['bootstrap', 'ccp_alpha', 'class_weight', 'criterion', 'max_depth', 'max_features', 'max_leaf_nodes', 'max_samples', 'min_impurity_decrease', 'min_impurity_split', 'min_samples_leaf', 'min_samples_split', 'min_weight_fraction_leaf', 'n_estimators', 'n_jobs', 'oob_score', 'random_state', 'verbose', 'warm_start'])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': [True, False],\n",
      " 'max_depth': [10, 60, 110, None],\n",
      " 'max_features': ['auto', 'sqrt'],\n",
      " 'min_samples_leaf': [1, 2, 4],\n",
      " 'min_samples_split': [2, 5, 10],\n",
      " 'n_estimators': [200, 1100, 2000]}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 3)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 3)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "pprint(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:  2.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, estimator=RandomForestRegressor(), n_jobs=-1,\n",
       "                   param_distributions={'bootstrap': [True, False],\n",
       "                                        'max_depth': [10, 60, 110, None],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [200, 1100, 2000]},\n",
       "                   random_state=42, verbose=2)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestRegressor()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 10, cv = 3, verbose=2, random_state=42, n_jobs = -1)# Fit the random search model\n",
    "rf_random.fit(X_train_minmax, encoded_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 200,\n",
       " 'min_samples_split': 2,\n",
       " 'min_samples_leaf': 4,\n",
       " 'max_features': 'auto',\n",
       " 'max_depth': None,\n",
       " 'bootstrap': True}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Fit Hypertuned Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Testing Score: 0.9050343249427918\n"
     ]
    }
   ],
   "source": [
    "rf2 = RandomForestClassifier(n_estimators=200, min_samples_split =2, min_samples_leaf = 2, max_features='auto', max_depth=None, bootstrap='True')\n",
    "rf2 = rf2.fit(X_train_minmax, encoded_y_train)\n",
    "score = rf2.score(X_test_minmax, encoded_y_test)\n",
    "\n",
    "print(f\"Random Forest Testing Score: {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Models/lmstein_rf.sav']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "filename = 'Models/lmstein_rf.sav'\n",
    "joblib.dump(\"lmstein\", filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kNN Model\n",
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: 1, Train/Test Score: 1.000/0.795\n",
      "k: 3, Train/Test Score: 0.891/0.791\n",
      "k: 5, Train/Test Score: 0.864/0.789\n",
      "k: 7, Train/Test Score: 0.846/0.791\n",
      "k: 9, Train/Test Score: 0.833/0.797\n",
      "k: 11, Train/Test Score: 0.828/0.796\n",
      "k: 13, Train/Test Score: 0.829/0.798\n",
      "k: 15, Train/Test Score: 0.824/0.802\n",
      "k: 17, Train/Test Score: 0.824/0.793\n",
      "k: 19, Train/Test Score: 0.819/0.788\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Identify optimal k value\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "for k in range(1, 20, 2):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train_minmax, y_train)\n",
    "    train_score = knn.score(X_train_minmax, y_train)\n",
    "    test_score = knn.score(X_test_minmax, y_test)\n",
    "    train_scores.append(train_score)\n",
    "    test_scores.append(test_score)\n",
    "    print(f\"k: {k}, Train/Test Score: {train_score:.3f}/{test_score:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot k values\n",
    "plt.plot(range(1, 20, 2), train_scores, marker='o')\n",
    "plt.plot(range(1, 20, 2), test_scores, marker=\"x\")\n",
    "plt.xlabel(\"k neighbors\")\n",
    "plt.ylabel(\"Testing accuracy Score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=9 Test Acc: 0.797\n"
     ]
    }
   ],
   "source": [
    "# Use optimal k value to run kNN and score\n",
    "knn = KNeighborsClassifier(n_neighbors=9)\n",
    "knn.fit(X_train_minmax, y_train)\n",
    "print('k=9 Test Acc: %.3f' % knn.score(X_test_minmax, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypertune the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['algorithm', 'leaf_size', 'metric', 'metric_params', 'n_jobs', 'n_neighbors', 'p', 'weights'])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done  72 out of  72 | elapsed:    2.0s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "grid_params = {\n",
    "    'n_neighbors': [3,5,7,9,11,19],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan']\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(KNeighborsClassifier(),grid_params, verbose = 1, cv=3,n_jobs=-1)\n",
    "gs_results = gs.fit(X_train_minmax, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'metric': 'manhattan', 'n_neighbors': 9, 'weights': 'distance'}\n",
      "Best SVG score: 0.8020216197146509\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best Parameters: {gs_results.best_params_}\")\n",
    "print(f\"Best SVG score: {gs_results.best_score_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Hypertuned Model and Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hypertuned kNN Test Acc: 0.810\n"
     ]
    }
   ],
   "source": [
    "knn2 = KNeighborsClassifier(metric='manhattan', weights='distance', n_neighbors=9)\n",
    "knn2.fit(X_train_minmax, y_train)\n",
    "print('Hypertuned kNN Test Acc: %.3f' % knn2.score(X_test_minmax, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Models/lmstein_knn.sav']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "filename = 'Models/lmstein_knn.sav'\n",
    "joblib.dump(\"lmstein\", filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normal Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 4)                 76        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 15        \n",
      "=================================================================\n",
      "Total params: 91\n",
      "Trainable params: 91\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "#Define number of inputs (features) and add to model\n",
    "model=Sequential()\n",
    "number_inputs = 18\n",
    "number_hidden_nodes = 4\n",
    "model.add(Dense(units=number_hidden_nodes,activation='relu', input_dim=number_inputs))\n",
    "\n",
    "#Define number of output classes and add to model\n",
    "number_classes = 3\n",
    "model.add(Dense(units=number_classes, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5243 samples\n",
      "Epoch 1/100\n",
      "5243/5243 - 1s - loss: 1.0455 - accuracy: 0.3221\n",
      "Epoch 2/100\n",
      "5243/5243 - 0s - loss: 0.8896 - accuracy: 0.5056\n",
      "Epoch 3/100\n",
      "5243/5243 - 0s - loss: 0.7419 - accuracy: 0.5295\n",
      "Epoch 4/100\n",
      "5243/5243 - 0s - loss: 0.6402 - accuracy: 0.7009\n",
      "Epoch 5/100\n",
      "5243/5243 - 0s - loss: 0.5757 - accuracy: 0.7370\n",
      "Epoch 6/100\n",
      "5243/5243 - 0s - loss: 0.5317 - accuracy: 0.7442\n",
      "Epoch 7/100\n",
      "5243/5243 - 0s - loss: 0.5015 - accuracy: 0.7448\n",
      "Epoch 8/100\n",
      "5243/5243 - 0s - loss: 0.4798 - accuracy: 0.7456\n",
      "Epoch 9/100\n",
      "5243/5243 - 0s - loss: 0.4638 - accuracy: 0.7461\n",
      "Epoch 10/100\n",
      "5243/5243 - 0s - loss: 0.4515 - accuracy: 0.7463\n",
      "Epoch 11/100\n",
      "5243/5243 - 0s - loss: 0.4417 - accuracy: 0.7475\n",
      "Epoch 12/100\n",
      "5243/5243 - 0s - loss: 0.4338 - accuracy: 0.7480\n",
      "Epoch 13/100\n",
      "5243/5243 - 0s - loss: 0.4273 - accuracy: 0.7496\n",
      "Epoch 14/100\n",
      "5243/5243 - 0s - loss: 0.4218 - accuracy: 0.7700\n",
      "Epoch 15/100\n",
      "5243/5243 - 0s - loss: 0.4169 - accuracy: 0.7778\n",
      "Epoch 16/100\n",
      "5243/5243 - 0s - loss: 0.4125 - accuracy: 0.7974\n",
      "Epoch 17/100\n",
      "5243/5243 - 0s - loss: 0.4087 - accuracy: 0.7946\n",
      "Epoch 18/100\n",
      "5243/5243 - 0s - loss: 0.4052 - accuracy: 0.7955\n",
      "Epoch 19/100\n",
      "5243/5243 - 0s - loss: 0.4020 - accuracy: 0.7978\n",
      "Epoch 20/100\n",
      "5243/5243 - 0s - loss: 0.3990 - accuracy: 0.7950\n",
      "Epoch 21/100\n",
      "5243/5243 - 0s - loss: 0.3961 - accuracy: 0.7931\n",
      "Epoch 22/100\n",
      "5243/5243 - 0s - loss: 0.3934 - accuracy: 0.7929\n",
      "Epoch 23/100\n",
      "5243/5243 - 0s - loss: 0.3910 - accuracy: 0.7959\n",
      "Epoch 24/100\n",
      "5243/5243 - 0s - loss: 0.3888 - accuracy: 0.7944\n",
      "Epoch 25/100\n",
      "5243/5243 - 0s - loss: 0.3866 - accuracy: 0.7973\n",
      "Epoch 26/100\n",
      "5243/5243 - 0s - loss: 0.3845 - accuracy: 0.7948\n",
      "Epoch 27/100\n",
      "5243/5243 - 0s - loss: 0.3826 - accuracy: 0.7978\n",
      "Epoch 28/100\n",
      "5243/5243 - 0s - loss: 0.3809 - accuracy: 0.7925\n",
      "Epoch 29/100\n",
      "5243/5243 - 0s - loss: 0.3790 - accuracy: 0.7976\n",
      "Epoch 30/100\n",
      "5243/5243 - 0s - loss: 0.3775 - accuracy: 0.7982\n",
      "Epoch 31/100\n",
      "5243/5243 - 0s - loss: 0.3760 - accuracy: 0.8030\n",
      "Epoch 32/100\n",
      "5243/5243 - 0s - loss: 0.3746 - accuracy: 0.8011\n",
      "Epoch 33/100\n",
      "5243/5243 - 0s - loss: 0.3735 - accuracy: 0.8011\n",
      "Epoch 34/100\n",
      "5243/5243 - 0s - loss: 0.3720 - accuracy: 0.8003\n",
      "Epoch 35/100\n",
      "5243/5243 - 0s - loss: 0.3708 - accuracy: 0.8030\n",
      "Epoch 36/100\n",
      "5243/5243 - 0s - loss: 0.3696 - accuracy: 0.8026\n",
      "Epoch 37/100\n",
      "5243/5243 - 0s - loss: 0.3676 - accuracy: 0.8035\n",
      "Epoch 38/100\n",
      "5243/5243 - 0s - loss: 0.3667 - accuracy: 0.8047\n",
      "Epoch 39/100\n",
      "5243/5243 - 0s - loss: 0.3658 - accuracy: 0.8051\n",
      "Epoch 40/100\n",
      "5243/5243 - 0s - loss: 0.3649 - accuracy: 0.8079\n",
      "Epoch 41/100\n",
      "5243/5243 - 0s - loss: 0.3639 - accuracy: 0.8076\n",
      "Epoch 42/100\n",
      "5243/5243 - 0s - loss: 0.3630 - accuracy: 0.8091\n",
      "Epoch 43/100\n",
      "5243/5243 - 0s - loss: 0.3624 - accuracy: 0.8104\n",
      "Epoch 44/100\n",
      "5243/5243 - 0s - loss: 0.3614 - accuracy: 0.8114\n",
      "Epoch 45/100\n",
      "5243/5243 - 0s - loss: 0.3611 - accuracy: 0.8116\n",
      "Epoch 46/100\n",
      "5243/5243 - 0s - loss: 0.3602 - accuracy: 0.8129\n",
      "Epoch 47/100\n",
      "5243/5243 - 0s - loss: 0.3596 - accuracy: 0.8137\n",
      "Epoch 48/100\n",
      "5243/5243 - 0s - loss: 0.3594 - accuracy: 0.8144\n",
      "Epoch 49/100\n",
      "5243/5243 - 0s - loss: 0.3592 - accuracy: 0.8156\n",
      "Epoch 50/100\n",
      "5243/5243 - 0s - loss: 0.3584 - accuracy: 0.8121\n",
      "Epoch 51/100\n",
      "5243/5243 - 0s - loss: 0.3577 - accuracy: 0.8150\n",
      "Epoch 52/100\n",
      "5243/5243 - 0s - loss: 0.3575 - accuracy: 0.8144\n",
      "Epoch 53/100\n",
      "5243/5243 - 0s - loss: 0.3571 - accuracy: 0.8133\n",
      "Epoch 54/100\n",
      "5243/5243 - 0s - loss: 0.3568 - accuracy: 0.8144\n",
      "Epoch 55/100\n",
      "5243/5243 - 0s - loss: 0.3561 - accuracy: 0.8152\n",
      "Epoch 56/100\n",
      "5243/5243 - 0s - loss: 0.3559 - accuracy: 0.8156\n",
      "Epoch 57/100\n",
      "5243/5243 - 0s - loss: 0.3552 - accuracy: 0.8129\n",
      "Epoch 58/100\n",
      "5243/5243 - 0s - loss: 0.3553 - accuracy: 0.8152\n",
      "Epoch 59/100\n",
      "5243/5243 - 0s - loss: 0.3547 - accuracy: 0.8182\n",
      "Epoch 60/100\n",
      "5243/5243 - 0s - loss: 0.3545 - accuracy: 0.8152\n",
      "Epoch 61/100\n",
      "5243/5243 - 0s - loss: 0.3542 - accuracy: 0.8184\n",
      "Epoch 62/100\n",
      "5243/5243 - 0s - loss: 0.3537 - accuracy: 0.8173\n",
      "Epoch 63/100\n",
      "5243/5243 - 0s - loss: 0.3535 - accuracy: 0.8173\n",
      "Epoch 64/100\n",
      "5243/5243 - 0s - loss: 0.3535 - accuracy: 0.8146\n",
      "Epoch 65/100\n",
      "5243/5243 - 0s - loss: 0.3531 - accuracy: 0.8194\n",
      "Epoch 66/100\n",
      "5243/5243 - 0s - loss: 0.3526 - accuracy: 0.8184\n",
      "Epoch 67/100\n",
      "5243/5243 - 0s - loss: 0.3529 - accuracy: 0.8177\n",
      "Epoch 68/100\n",
      "5243/5243 - 0s - loss: 0.3527 - accuracy: 0.8190\n",
      "Epoch 69/100\n",
      "5243/5243 - 0s - loss: 0.3523 - accuracy: 0.8180\n",
      "Epoch 70/100\n",
      "5243/5243 - 0s - loss: 0.3521 - accuracy: 0.8161\n",
      "Epoch 71/100\n",
      "5243/5243 - 0s - loss: 0.3521 - accuracy: 0.8180\n",
      "Epoch 72/100\n",
      "5243/5243 - 0s - loss: 0.3516 - accuracy: 0.8192\n",
      "Epoch 73/100\n",
      "5243/5243 - 0s - loss: 0.3513 - accuracy: 0.8179\n",
      "Epoch 74/100\n",
      "5243/5243 - 0s - loss: 0.3513 - accuracy: 0.8182\n",
      "Epoch 75/100\n",
      "5243/5243 - 0s - loss: 0.3513 - accuracy: 0.8180\n",
      "Epoch 76/100\n",
      "5243/5243 - 0s - loss: 0.3510 - accuracy: 0.8236\n",
      "Epoch 77/100\n",
      "5243/5243 - 0s - loss: 0.3509 - accuracy: 0.8200\n",
      "Epoch 78/100\n",
      "5243/5243 - 0s - loss: 0.3506 - accuracy: 0.8169\n",
      "Epoch 79/100\n",
      "5243/5243 - 0s - loss: 0.3500 - accuracy: 0.8194\n",
      "Epoch 80/100\n",
      "5243/5243 - 0s - loss: 0.3506 - accuracy: 0.8158\n",
      "Epoch 81/100\n",
      "5243/5243 - 0s - loss: 0.3504 - accuracy: 0.8177\n",
      "Epoch 82/100\n",
      "5243/5243 - 0s - loss: 0.3501 - accuracy: 0.8169\n",
      "Epoch 83/100\n",
      "5243/5243 - 0s - loss: 0.3501 - accuracy: 0.8196\n",
      "Epoch 84/100\n",
      "5243/5243 - 0s - loss: 0.3495 - accuracy: 0.8182\n",
      "Epoch 85/100\n",
      "5243/5243 - 0s - loss: 0.3503 - accuracy: 0.8201\n",
      "Epoch 86/100\n",
      "5243/5243 - 0s - loss: 0.3498 - accuracy: 0.8173\n",
      "Epoch 87/100\n",
      "5243/5243 - 0s - loss: 0.3490 - accuracy: 0.8211\n",
      "Epoch 88/100\n",
      "5243/5243 - 0s - loss: 0.3495 - accuracy: 0.8194\n",
      "Epoch 89/100\n",
      "5243/5243 - 0s - loss: 0.3490 - accuracy: 0.8194\n",
      "Epoch 90/100\n",
      "5243/5243 - 0s - loss: 0.3490 - accuracy: 0.8198\n",
      "Epoch 91/100\n",
      "5243/5243 - 0s - loss: 0.3489 - accuracy: 0.8215\n",
      "Epoch 92/100\n",
      "5243/5243 - 0s - loss: 0.3486 - accuracy: 0.8222\n",
      "Epoch 93/100\n",
      "5243/5243 - 0s - loss: 0.3492 - accuracy: 0.8201\n",
      "Epoch 94/100\n",
      "5243/5243 - 0s - loss: 0.3489 - accuracy: 0.8205\n",
      "Epoch 95/100\n",
      "5243/5243 - 0s - loss: 0.3486 - accuracy: 0.8205\n",
      "Epoch 96/100\n",
      "5243/5243 - 0s - loss: 0.3484 - accuracy: 0.8194\n",
      "Epoch 97/100\n",
      "5243/5243 - 0s - loss: 0.3485 - accuracy: 0.8224\n",
      "Epoch 98/100\n",
      "5243/5243 - 0s - loss: 0.3483 - accuracy: 0.8230\n",
      "Epoch 99/100\n",
      "5243/5243 - 0s - loss: 0.3482 - accuracy: 0.8222\n",
      "Epoch 100/100\n",
      "5243/5243 - 0s - loss: 0.3480 - accuracy: 0.8186\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa8bf1662e8>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit the model to training dataset\n",
    "model.fit(\n",
    "    X_train_minmax,\n",
    "    y_train_categorical,\n",
    "    epochs=100,\n",
    "    shuffle=True,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1748/1 - 0s - loss: 0.3559 - accuracy: 0.8049\n",
      "Loss: 0.37313833539491387, Accuracy: 0.8049198985099792\n"
     ]
    }
   ],
   "source": [
    "#Quantify the model\n",
    "model_loss, model_accuracy = model.evaluate(\n",
    "    X_test_minmax, y_test_categorical, verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 6)                 114       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 6)                 42        \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 3)                 21        \n",
      "=================================================================\n",
      "Total params: 177\n",
      "Trainable params: 177\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Creat the model\n",
    "deep_model = Sequential()\n",
    "deep_model.add(Dense(units=6, activation='relu', input_dim=number_inputs))\n",
    "deep_model.add(Dense(units=6, activation='relu'))\n",
    "deep_model.add(Dense(units=number_classes, activation='softmax'))\n",
    "deep_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5243 samples\n",
      "Epoch 1/100\n",
      "5243/5243 - 1s - loss: 0.9560 - accuracy: 0.4566\n",
      "Epoch 2/100\n",
      "5243/5243 - 0s - loss: 0.6651 - accuracy: 0.6592\n",
      "Epoch 3/100\n",
      "5243/5243 - 0s - loss: 0.5166 - accuracy: 0.7521\n",
      "Epoch 4/100\n",
      "5243/5243 - 0s - loss: 0.4478 - accuracy: 0.7627\n",
      "Epoch 5/100\n",
      "5243/5243 - 0s - loss: 0.4121 - accuracy: 0.7784\n",
      "Epoch 6/100\n",
      "5243/5243 - 0s - loss: 0.3980 - accuracy: 0.7858\n",
      "Epoch 7/100\n",
      "5243/5243 - 0s - loss: 0.3904 - accuracy: 0.7854\n",
      "Epoch 8/100\n",
      "5243/5243 - 0s - loss: 0.3861 - accuracy: 0.7892\n",
      "Epoch 9/100\n",
      "5243/5243 - 0s - loss: 0.3827 - accuracy: 0.7862\n",
      "Epoch 10/100\n",
      "5243/5243 - 0s - loss: 0.3801 - accuracy: 0.7879\n",
      "Epoch 11/100\n",
      "5243/5243 - 0s - loss: 0.3784 - accuracy: 0.7915\n",
      "Epoch 12/100\n",
      "5243/5243 - 0s - loss: 0.3767 - accuracy: 0.7900\n",
      "Epoch 13/100\n",
      "5243/5243 - 0s - loss: 0.3753 - accuracy: 0.7864\n",
      "Epoch 14/100\n",
      "5243/5243 - 0s - loss: 0.3741 - accuracy: 0.7910\n",
      "Epoch 15/100\n",
      "5243/5243 - 0s - loss: 0.3733 - accuracy: 0.7883\n",
      "Epoch 16/100\n",
      "5243/5243 - 0s - loss: 0.3725 - accuracy: 0.7854\n",
      "Epoch 17/100\n",
      "5243/5243 - 0s - loss: 0.3710 - accuracy: 0.7923\n",
      "Epoch 18/100\n",
      "5243/5243 - 0s - loss: 0.3703 - accuracy: 0.7883\n",
      "Epoch 19/100\n",
      "5243/5243 - 0s - loss: 0.3697 - accuracy: 0.7967\n",
      "Epoch 20/100\n",
      "5243/5243 - 0s - loss: 0.3695 - accuracy: 0.7934\n",
      "Epoch 21/100\n",
      "5243/5243 - 0s - loss: 0.3679 - accuracy: 0.7974\n",
      "Epoch 22/100\n",
      "5243/5243 - 0s - loss: 0.3679 - accuracy: 0.7950\n",
      "Epoch 23/100\n",
      "5243/5243 - 0s - loss: 0.3671 - accuracy: 0.7938\n",
      "Epoch 24/100\n",
      "5243/5243 - 0s - loss: 0.3668 - accuracy: 0.7946\n",
      "Epoch 25/100\n",
      "5243/5243 - 0s - loss: 0.3661 - accuracy: 0.7940\n",
      "Epoch 26/100\n",
      "5243/5243 - 0s - loss: 0.3653 - accuracy: 0.7953\n",
      "Epoch 27/100\n",
      "5243/5243 - 0s - loss: 0.3652 - accuracy: 0.8003\n",
      "Epoch 28/100\n",
      "5243/5243 - 0s - loss: 0.3647 - accuracy: 0.7973\n",
      "Epoch 29/100\n",
      "5243/5243 - 0s - loss: 0.3642 - accuracy: 0.8030\n",
      "Epoch 30/100\n",
      "5243/5243 - 0s - loss: 0.3635 - accuracy: 0.7995\n",
      "Epoch 31/100\n",
      "5243/5243 - 0s - loss: 0.3632 - accuracy: 0.8037\n",
      "Epoch 32/100\n",
      "5243/5243 - 0s - loss: 0.3626 - accuracy: 0.8043\n",
      "Epoch 33/100\n",
      "5243/5243 - 0s - loss: 0.3615 - accuracy: 0.8030\n",
      "Epoch 34/100\n",
      "5243/5243 - 0s - loss: 0.3622 - accuracy: 0.8030\n",
      "Epoch 35/100\n",
      "5243/5243 - 0s - loss: 0.3609 - accuracy: 0.8060\n",
      "Epoch 36/100\n",
      "5243/5243 - 0s - loss: 0.3611 - accuracy: 0.8079\n",
      "Epoch 37/100\n",
      "5243/5243 - 0s - loss: 0.3598 - accuracy: 0.8049\n",
      "Epoch 38/100\n",
      "5243/5243 - 0s - loss: 0.3591 - accuracy: 0.8085\n",
      "Epoch 39/100\n",
      "5243/5243 - 0s - loss: 0.3584 - accuracy: 0.8117\n",
      "Epoch 40/100\n",
      "5243/5243 - 0s - loss: 0.3580 - accuracy: 0.8070\n",
      "Epoch 41/100\n",
      "5243/5243 - 0s - loss: 0.3578 - accuracy: 0.8142\n",
      "Epoch 42/100\n",
      "5243/5243 - 0s - loss: 0.3571 - accuracy: 0.8087\n",
      "Epoch 43/100\n",
      "5243/5243 - 0s - loss: 0.3568 - accuracy: 0.8102\n",
      "Epoch 44/100\n",
      "5243/5243 - 0s - loss: 0.3557 - accuracy: 0.8119\n",
      "Epoch 45/100\n",
      "5243/5243 - 0s - loss: 0.3564 - accuracy: 0.8074\n",
      "Epoch 46/100\n",
      "5243/5243 - 0s - loss: 0.3554 - accuracy: 0.8114\n",
      "Epoch 47/100\n",
      "5243/5243 - 0s - loss: 0.3543 - accuracy: 0.8179\n",
      "Epoch 48/100\n",
      "5243/5243 - 0s - loss: 0.3536 - accuracy: 0.8129\n",
      "Epoch 49/100\n",
      "5243/5243 - 0s - loss: 0.3538 - accuracy: 0.8135\n",
      "Epoch 50/100\n",
      "5243/5243 - 0s - loss: 0.3528 - accuracy: 0.8150\n",
      "Epoch 51/100\n",
      "5243/5243 - 0s - loss: 0.3535 - accuracy: 0.8167\n",
      "Epoch 52/100\n",
      "5243/5243 - 0s - loss: 0.3519 - accuracy: 0.8196\n",
      "Epoch 53/100\n",
      "5243/5243 - 0s - loss: 0.3527 - accuracy: 0.8159\n",
      "Epoch 54/100\n",
      "5243/5243 - 0s - loss: 0.3523 - accuracy: 0.8179\n",
      "Epoch 55/100\n",
      "5243/5243 - 0s - loss: 0.3515 - accuracy: 0.8182\n",
      "Epoch 56/100\n",
      "5243/5243 - 0s - loss: 0.3511 - accuracy: 0.8201\n",
      "Epoch 57/100\n",
      "5243/5243 - 0s - loss: 0.3509 - accuracy: 0.8190\n",
      "Epoch 58/100\n",
      "5243/5243 - 0s - loss: 0.3508 - accuracy: 0.8211\n",
      "Epoch 59/100\n",
      "5243/5243 - 0s - loss: 0.3500 - accuracy: 0.8190\n",
      "Epoch 60/100\n",
      "5243/5243 - 0s - loss: 0.3498 - accuracy: 0.8207\n",
      "Epoch 61/100\n",
      "5243/5243 - 0s - loss: 0.3499 - accuracy: 0.8188\n",
      "Epoch 62/100\n",
      "5243/5243 - 0s - loss: 0.3492 - accuracy: 0.8184\n",
      "Epoch 63/100\n",
      "5243/5243 - 0s - loss: 0.3492 - accuracy: 0.8205\n",
      "Epoch 64/100\n",
      "5243/5243 - 0s - loss: 0.3488 - accuracy: 0.8200\n",
      "Epoch 65/100\n",
      "5243/5243 - 0s - loss: 0.3487 - accuracy: 0.8192\n",
      "Epoch 66/100\n",
      "5243/5243 - 0s - loss: 0.3488 - accuracy: 0.8203\n",
      "Epoch 67/100\n",
      "5243/5243 - 0s - loss: 0.3502 - accuracy: 0.8169\n",
      "Epoch 68/100\n",
      "5243/5243 - 0s - loss: 0.3479 - accuracy: 0.8186\n",
      "Epoch 69/100\n",
      "5243/5243 - 0s - loss: 0.3475 - accuracy: 0.8228\n",
      "Epoch 70/100\n",
      "5243/5243 - 0s - loss: 0.3474 - accuracy: 0.8228\n",
      "Epoch 71/100\n",
      "5243/5243 - 0s - loss: 0.3473 - accuracy: 0.8226\n",
      "Epoch 72/100\n",
      "5243/5243 - 0s - loss: 0.3472 - accuracy: 0.8243\n",
      "Epoch 73/100\n",
      "5243/5243 - 0s - loss: 0.3469 - accuracy: 0.8209\n",
      "Epoch 74/100\n",
      "5243/5243 - 0s - loss: 0.3472 - accuracy: 0.8236\n",
      "Epoch 75/100\n",
      "5243/5243 - 0s - loss: 0.3462 - accuracy: 0.8255\n",
      "Epoch 76/100\n",
      "5243/5243 - 0s - loss: 0.3465 - accuracy: 0.8238\n",
      "Epoch 77/100\n",
      "5243/5243 - 0s - loss: 0.3467 - accuracy: 0.8243\n",
      "Epoch 78/100\n",
      "5243/5243 - 0s - loss: 0.3455 - accuracy: 0.8257\n",
      "Epoch 79/100\n",
      "5243/5243 - 0s - loss: 0.3461 - accuracy: 0.8243\n",
      "Epoch 80/100\n",
      "5243/5243 - 0s - loss: 0.3453 - accuracy: 0.8255\n",
      "Epoch 81/100\n",
      "5243/5243 - 0s - loss: 0.3456 - accuracy: 0.8220\n",
      "Epoch 82/100\n",
      "5243/5243 - 0s - loss: 0.3445 - accuracy: 0.8293\n",
      "Epoch 83/100\n",
      "5243/5243 - 0s - loss: 0.3448 - accuracy: 0.8241\n",
      "Epoch 84/100\n",
      "5243/5243 - 0s - loss: 0.3448 - accuracy: 0.8264\n",
      "Epoch 85/100\n",
      "5243/5243 - 0s - loss: 0.3457 - accuracy: 0.8232\n",
      "Epoch 86/100\n",
      "5243/5243 - 0s - loss: 0.3441 - accuracy: 0.8262\n",
      "Epoch 87/100\n",
      "5243/5243 - 0s - loss: 0.3440 - accuracy: 0.8272\n",
      "Epoch 88/100\n",
      "5243/5243 - 0s - loss: 0.3447 - accuracy: 0.8224\n",
      "Epoch 89/100\n",
      "5243/5243 - 0s - loss: 0.3437 - accuracy: 0.8251\n",
      "Epoch 90/100\n",
      "5243/5243 - 0s - loss: 0.3435 - accuracy: 0.8272\n",
      "Epoch 91/100\n",
      "5243/5243 - 0s - loss: 0.3422 - accuracy: 0.8259\n",
      "Epoch 92/100\n",
      "5243/5243 - 0s - loss: 0.3431 - accuracy: 0.8280\n",
      "Epoch 93/100\n",
      "5243/5243 - 0s - loss: 0.3428 - accuracy: 0.8301\n",
      "Epoch 94/100\n",
      "5243/5243 - 0s - loss: 0.3435 - accuracy: 0.8222\n",
      "Epoch 95/100\n",
      "5243/5243 - 0s - loss: 0.3427 - accuracy: 0.8302\n",
      "Epoch 96/100\n",
      "5243/5243 - 0s - loss: 0.3423 - accuracy: 0.8287\n",
      "Epoch 97/100\n",
      "5243/5243 - 0s - loss: 0.3416 - accuracy: 0.8331\n",
      "Epoch 98/100\n",
      "5243/5243 - 0s - loss: 0.3413 - accuracy: 0.8322\n",
      "Epoch 99/100\n",
      "5243/5243 - 0s - loss: 0.3407 - accuracy: 0.8297\n",
      "Epoch 100/100\n",
      "5243/5243 - 0s - loss: 0.3414 - accuracy: 0.8247\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa8bf8137f0>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deep_model.compile(optimizer='adam',\n",
    "                   loss='categorical_crossentropy',\n",
    "                   metrics=['accuracy'])\n",
    "\n",
    "deep_model.fit(\n",
    "    X_train_minmax,\n",
    "    y_train_categorical,\n",
    "    epochs=100,\n",
    "    shuffle=True,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1748/1 - 0s - loss: 0.3475 - accuracy: 0.8169\n",
      "Deep Neural Network - Loss: 0.36368869228002954, Accuracy: 0.8169336318969727\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = deep_model.evaluate(X_test_minmax, y_test_categorical, verbose=2)\n",
    "print(f\"Deep Neural Network - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "dev"
  },
  "kernelspec": {
   "display_name": "Python [conda env:PythonAdv] *",
   "language": "python",
   "name": "conda-env-PythonAdv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "nteract": {
   "version": "0.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
